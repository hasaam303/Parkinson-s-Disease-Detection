# -*- coding: utf-8 -*-
"""Copy of Parkinson's_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_KgCy1zycv5WYR5Q4G0F8qFwfzcB6cuu
"""



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score



"""Data Collections and Analysis

"""

# loading the data from a csv file into a Pandas DataFrame

parkinsons_data =  pd.read_csv("/content/drive/MyDrive/Parkinson's dataset/parkinsons.csv")
parkinsons_data

# Display first 5 rows of the DataFrame
parkinsons_data.head()

# of rows and columns in the DataFrame
parkinsons_data.shape

# info on dataset

parkinsons_data.info()

# checking for missing values in each column

parkinsons_data.isnull().sum()

# statistical measures on the data

parkinsons_data.describe()

# distribution of target varible
parkinsons_data['status'].value_counts()

# grouping ]the data based on target variable (status)
parkinsons_data.groupby('status').mean(numeric_only=True)

# data processing
x = parkinsons_data.drop(columns=["name","status"], axis = 1)
y = parkinsons_data['status']

print(x)

print(y)

# Splitting the data into training and Test data
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=2)

print(x.shape, X_train.shape,X_test.shape)
# the second tuple shows the amount that will be used the train the model (80%) and the third tuple shows the amount that will be used to test (20%)

# data standardization
scaler = StandardScaler()



scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

print(X_train)

# Model Training
# Support Vector Machine Model
model = svm.SVC(kernel='linear')

# training the SVM model with training data
model.fit(X_train, Y_train)

# Model evaluation and accuracy score
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print('Accuracy score of trianing data:', training_data_accuracy)

# accuracy on training data
X_test_predition = model.predict(X_test)
test_data_accuracy = accuracy_score(Y_test, X_test_predition)

print("Accuracy score of test data: ", test_data_accuracy)

# building a predictive system
input_data = (162.56800,198.34600,77.63000,0.00502,0.00003,0.00280,0.00253,0.00841,0.01791,0.16800,0.00793,0.01057,0.01799,0.02380,0.01170,25.67800,0.427785,0.723797,-6.635729,0.209866,1.957961,0.135242)

# change tuple into numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

prediction = model.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print("The person does not have parkinsons disease")
else:
  print("The person has parkinsons disease")

